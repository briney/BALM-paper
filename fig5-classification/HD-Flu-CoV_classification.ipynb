{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ffc9d0-5674-4399-8318-15aa50fdf4fd",
   "metadata": {},
   "source": [
    "### HD vs Flu vs CoV classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f359d750-75e6-46db-a2ba-16701e01c135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    RobertaTokenizer,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from datasets import (\n",
    "    DatasetDict,\n",
    "    ClassLabel,\n",
    "    load_dataset,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    matthews_corrcoef,\n",
    ")\n",
    "\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "from datetime import date\n",
    "import wandb\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7c83e4-5d28-4b6e-9329-40244a6cc17b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace with actual model path\n",
    "checkpoint = './BALM-paired/'\n",
    "\n",
    "# model name for run name & saving\n",
    "model_str = \"BALM-paired\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab7336-79aa-4963-a854-5aa7b8dcef97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"../tokenizer/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73b6391-f608-4bc5-9b76-23da04f12c47",
   "metadata": {},
   "source": [
    "### Process and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a09c5c-67b0-451a-af36-91b032071282",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(\n",
    "    batch, \n",
    "    tokenizer=None, \n",
    "    tokenizer_path=\"./tokenizer\", \n",
    "    separator=\"</s>\",\n",
    "    max_len=512\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    docstring\n",
    "    \"\"\"\n",
    "    # set up tokenizer if not provided\n",
    "    if tokenizer is None:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_path, max_len=max_len)\n",
    "        \n",
    "    # tokenize the H/L sequence pair\n",
    "    sequences = [h + separator + l for h, l in zip(batch[\"h_sequence\"], batch[\"l_sequence\"])]\n",
    "    tokenized = tokenizer(sequences, padding=\"max_length\", max_length=max_len)\n",
    "    batch[\"input_ids\"] = tokenized.input_ids\n",
    "    batch[\"attention_mask\"] = tokenized.attention_mask\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdce4ae0-fefd-485d-a383-f947463fd12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class_labels = ClassLabel(names=['Healthy-Donor', 'Flu-specific', 'CoV-specific'])\n",
    "n_classes = len(class_labels.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a0a3e1-a46e-4325-8d15-2f84d20efba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dataset provided in zenodo is the full dataset (not split into train-test)\n",
    "# so you'll need to do your dataset split(s) first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb67da7-e9e2-4e44-834e-8e7a084ad4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "itr_datasets = []\n",
    "for i in range(5):\n",
    "    data_files = DatasetDict({\n",
    "        'train': f'./datasets/HD-Flu-CoV/hd-0_flu-1_cov-2_train{i}.csv',\n",
    "        'test': f'./datasets/HD-Flu-CoV/hd-0_flu-1_cov-2_test{i}.csv'\n",
    "    })\n",
    "    split_dataset = load_dataset('csv', data_files=data_files)\n",
    "    itr_datasets.append(split_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784bcf94-d58e-4a11-afec-0523e4bd8333",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4595b7ea-8777-4370-b438-606ec3e65eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized = []\n",
    "for dataset in itr_datasets:\n",
    "    tokenized_dataset = dataset.map(\n",
    "        preprocess_dataset,\n",
    "        fn_kwargs={\n",
    "            \"tokenizer\": tokenizer,\n",
    "            \"max_len\": 320,\n",
    "        },\n",
    "        batched=True,\n",
    "        remove_columns=[\"name\", \"h_sequence\", \"l_sequence\"]\n",
    "    )\n",
    "    tokenized.append(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2361b6-8fd4-460a-9a0a-dae1c2b18a8f",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98757bc-2571-48fc-9ee9-8c6be1063434",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label2id = {\"Healthy-Donor\": 0, \"Flu-specific\": 1, \"CoV-specific\": 2}\n",
    "id2label = {0: \"Healthy-Donor\", 1: \"Flu-specific\", 2: \"CoV-specific\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236e429d-50ea-43ca-8881-bdc20a74ec3f",
   "metadata": {},
   "source": [
    "Multi-class Metrics:\n",
    "* https://www.evidentlyai.com/classification-metrics/multi-class-metrics\n",
    "* https://www.kaggle.com/code/nkitgupta/evaluation-metrics-for-multi-class-classification\n",
    "* https://discuss.huggingface.co/t/combining-metrics-for-multiclass-predictions-evaluations/21792/11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc759e29-2537-473e-902f-14afa2b883b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fig 5 presents accuracy, macro-f1, and mcc\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"macro-precision\": precision_score(labels, preds, average='macro'),\n",
    "        \"macro-recall\": recall_score(labels, preds, average='macro'),\n",
    "        \"macro-f1\": f1_score(labels, preds, average='macro'),\n",
    "        \"micro-precision\": precision_score(labels, preds, average='micro'),\n",
    "        \"micro-recall\": recall_score(labels, preds, average='micro'),\n",
    "        \"micro-f1\": f1_score(labels, preds, average='micro'),\n",
    "        \"mcc\": matthews_corrcoef(labels, preds),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272a52ef-cddb-4dbf-985d-d59def01e4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_results = pd.DataFrame({\"itr\": [],\n",
    "                             \"test_loss\": [],\n",
    "                             \"test_accuracy\": [],\n",
    "                             \"test_macro-precision\": [],\n",
    "                             \"test_macro-recall\": [],\n",
    "                             \"test_macro-f1\": [],\n",
    "                             \"test_micro-precision\": [],\n",
    "                             \"test_micro-recall\": [],\n",
    "                             \"test_micro-f1\": [],\n",
    "                             \"mcc\": []\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77223cf-e6d2-41bd-a5a9-3c610c4e43b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for itr, dataset in enumerate(tokenized):\n",
    "    run_name = f\"{model_str}_HD-Flu-CoV_itr-{itr}_{date.today().isoformat()}\"\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        checkpoint, \n",
    "        num_labels=n_classes,\n",
    "        label2id=label2id,\n",
    "        id2label=id2label,\n",
    "    )\n",
    "    # use this to freeze the base model weights + train only classification head\n",
    "    # for param in model.base_model.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    batch_size = 8 # on 1 gpu (ie. total batch size should equal 8)\n",
    "    lr = 5e-5\n",
    "    training_args = TrainingArguments(\n",
    "        evaluation_strategy = \"steps\",\n",
    "        logging_steps=10,\n",
    "        save_strategy=\"no\",\n",
    "        eval_steps=10,\n",
    "        learning_rate=lr,\n",
    "        per_device_train_batch_size=batch_size, \n",
    "        per_device_eval_batch_size=batch_size, \n",
    "        num_train_epochs=1,\n",
    "        warmup_ratio=0.1,\n",
    "        lr_scheduler_type='linear',\n",
    "\n",
    "        output_dir=f\"./checkpoints/{run_name}\",\n",
    "        seed=randint(0, 1024), \n",
    "        report_to=\"wandb\",\n",
    "        logging_dir=f\"./logs/{run_name}\",\n",
    "        logging_first_step=True,\n",
    "        run_name = run_name\n",
    "    )\n",
    "    \n",
    "    wandb.init(\n",
    "        project = 'specificity-class',\n",
    "        group=\"HD-Flu-CoV\",\n",
    "        job_type=model_str,\n",
    "        name = run_name,\n",
    "        dir = './',\n",
    "    )\n",
    "    \n",
    "    # train\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=dataset['train'],\n",
    "        eval_dataset=dataset['test'],\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(f\"./models/{run_name}\")\n",
    "    wandb.finish()\n",
    "    \n",
    "    # evaluate\n",
    "    logits, labels, metrics = trainer.predict(dataset['test'])\n",
    "    metrics['itr'] = itr\n",
    "    test_results = test_results.append(metrics, ignore_index=True)\n",
    "    \n",
    "    del model # delete to ensure untrained model is being trained for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7485c084-3feb-4b82-8a07-309a219d2c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_results.loc['mean'] = test_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b98b5b-2891-4845-b78e-0801a191a4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_results.loc['std'] = test_results.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fe73d-e094-4ace-8cba-39002c2f798a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_results.to_csv(f'./results/HD-Flu-CoV_{model_str}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
