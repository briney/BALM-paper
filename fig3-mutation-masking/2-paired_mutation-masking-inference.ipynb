{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3761fea2-5cbc-4246-aedf-564a0c0d5cd5",
   "metadata": {},
   "source": [
    "# Mutation masking inference for BALM-paired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3638a-ff3f-479e-80e5-b7b18bae5a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9f11b-012f-4370-b557-dcd7f3358938",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279516b-99bd-4bef-b9f0-3d562bfa03c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace with actual model path\n",
    "model_path = './BALM-paired/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1260b10-d9d1-41b4-92f8-15cc6114a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMaskedLM.from_pretrained(model_path).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9eb5bb-d303-449b-8dd3-ce7646da8f93",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c633a-f7df-4c1b-84de-771f506f9e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('../tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e815387-12a9-422e-9093-cf4247734e0d",
   "metadata": {},
   "source": [
    "## inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecc085-a2b0-41cf-9d8d-25fc89a28583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    pair_ids, \n",
    "    inputs, \n",
    "    labels, \n",
    "    germs,\n",
    "    device='cuda'\n",
    "):\n",
    "    '''\n",
    "    inputs and labels should already be tokenized\n",
    "    \n",
    "    labels should just be the 'input_ids' data, not the whole tokenized dict\n",
    "    '''\n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # pbar = tqdm(list(zip(pair_ids, inputs, labels)))\n",
    "        pbar = tqdm(list(zip(pair_ids, inputs, labels, germs)))\n",
    "        for name, i, l, g in pbar:\n",
    "            mask_positions = (i.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)\n",
    "            labels_ = torch.where(i.input_ids == tokenizer.mask_token_id, l, -100)\n",
    "            o = model(**i, labels=labels_)\n",
    "            \n",
    "            # loss\n",
    "            loss = o.loss.item()\n",
    "            \n",
    "            # PPL\n",
    "            perplexity = float(torch.exp(o.loss))\n",
    "            \n",
    "            # germlines\n",
    "            germs_ = torch.where(i.input_ids == tokenizer.mask_token_id, g, -100)\n",
    "            germ_tokens = [germs_[0, mask_pos] for mask_pos in mask_positions]\n",
    "            germ = [tokenizer.decode(germ_token) for germ_token in germ_tokens]\n",
    "            germ = \"\".join(germ)\n",
    "            \n",
    "            # ground truth\n",
    "            actual_tokens = [labels_[0, mask_pos] for mask_pos in mask_positions]\n",
    "            actual = [tokenizer.decode(actual_token) for actual_token in actual_tokens]\n",
    "            actual = \"\".join(actual)\n",
    "            \n",
    "            # logits\n",
    "            logits = [o.logits[0, mask_pos] for mask_pos in mask_positions][0]\n",
    "            m = torch.nn.Softmax(dim=1)\n",
    "            softmax = m(logits)\n",
    "            \n",
    "            # predictions\n",
    "            pred_tokens = logits.argmax(axis=-1)\n",
    "            preds = [tokenizer.decode(pred_token) for pred_token in pred_tokens]\n",
    "            predictions = ''.join(preds)\n",
    "            \n",
    "            # format and append data\n",
    "            for x in range(len(mask_positions[0])):\n",
    "                d = {\n",
    "                    \"pair_id\": name,\n",
    "                    \"perplexity\": perplexity,\n",
    "                    \"loss\": loss,\n",
    "                    \"mask_position\": mask_positions[0][x].item(),\n",
    "                    \"prediction\": predictions[x],\n",
    "                    \"germline\": germ[x],\n",
    "                    \"actual\": actual[x],\n",
    "                }\n",
    "                for y in range(tokenizer.vocab_size):\n",
    "                    _d = copy.deepcopy(d)\n",
    "                    token = tokenizer.decode(y)\n",
    "                    _d[\"token\"] = token\n",
    "                    _d[\"logit\"] = logits[x, y].item()\n",
    "                    _d[\"softmax\"] = softmax[x, y].item()\n",
    "                    data.append(_d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc21508-90bf-4285-ab49-ac4bbcd4bfef",
   "metadata": {},
   "source": [
    "## load labels & tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5868a07-bd0d-471b-b09e-d8df73a7a4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pair ids\n",
    "with open('./data/pair_ids.txt') as f:\n",
    "    pair_ids = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d58053-88ed-4055-b7a3-b9afb68ba52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# paired labels\n",
    "with open('./data/paired_labels.txt') as f:\n",
    "    paired_labels_txt = [line.strip() for line in f]\n",
    "\n",
    "paired_labels = [tokenizer(l, return_tensors='pt').to('cuda')['input_ids'] for l in paired_labels_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda3da36-154b-4a51-9210-c794badbeaf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# heavy germline labels\n",
    "with open('./data/light-masked_heavy-reverted.txt') as f:\n",
    "    lmasked_hreverted_txt = [line.strip() for line in f]\n",
    "\n",
    "hgerm_labels = [tokenizer(l, return_tensors='pt').to('cuda')['input_ids'] for l in lmasked_hreverted_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1ff30-5c3f-42e4-83e2-3c08908c46b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# light germline labels\n",
    "with open('./data/heavy-masked_light-reverted.txt') as f:\n",
    "    hmasked_lreverted_txt = [line.strip() for line in f]\n",
    "\n",
    "lgerm_labels = [tokenizer(l, return_tensors='pt').to('cuda')['input_ids'] for l in hmasked_lreverted_txt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4dd953-e736-4e04-809b-f1b408a87006",
   "metadata": {},
   "source": [
    "## masked heavy chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaff7fd-92f0-4019-bb63-5bc965e64935",
   "metadata": {},
   "source": [
    "#### mutated light chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ed392-bf52-48e4-9d60-b2e8ca4f58cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('reading masked data...')\n",
    "with open('./data/heavy-masked_light-mutated.txt') as f:\n",
    "    hmasked_lmutated_txt = [line.strip() for line in f]\n",
    "hmasked_lmutated = [tokenizer(l, return_tensors='pt').to(\"cuda\") for l in hmasked_lmutated_txt]\n",
    "\n",
    "print('running inference:')\n",
    "hmasked_lmutated_data = infer(model,\n",
    "                              tokenizer,\n",
    "                              pair_ids,\n",
    "                              hmasked_lmutated,\n",
    "                              paired_labels,\n",
    "                              hgerm_labels,\n",
    "                             )\n",
    "\n",
    "print('writing output...')\n",
    "hmasked_lmutated_df = pd.DataFrame(hmasked_lmutated_data)\n",
    "hmasked_lmutated_df.to_csv('./outputs/BALM-paired/heavy-masked_light-mutated.csv',\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0961f8-acb1-4b1c-81b5-62f1c85612fb",
   "metadata": {},
   "source": [
    "#### germline reverted light chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59716403-47c8-4895-8d8f-48fdcc90fe70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('reading masked data...')\n",
    "with open('./data/heavy-masked_light-reverted.txt') as f:\n",
    "    hmasked_lreverted_txt = [line.strip() for line in f]\n",
    "hmasked_lreverted = [tokenizer(l, return_tensors='pt').to(\"cuda\") for l in hmasked_lreverted_txt]\n",
    "\n",
    "print('running inference:')\n",
    "hmasked_lreverted_data = infer(model,\n",
    "                              tokenizer,\n",
    "                              pair_ids,\n",
    "                              hmasked_lreverted,\n",
    "                              paired_labels,\n",
    "                              hgerm_labels,\n",
    "                              )\n",
    "\n",
    "print('writing output...')\n",
    "hmasked_lreverted_df = pd.DataFrame(hmasked_lreverted_data)\n",
    "hmasked_lreverted_df.to_csv('./outputs/BALM-paired/heavy-masked_light-reverted.csv',\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d06ff-0a01-4e6d-822f-409ec9ac79e0",
   "metadata": {},
   "source": [
    "## masked light chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b1b879-4847-4337-994a-f4fa7a18b42b",
   "metadata": {},
   "source": [
    "#### mutated heavy chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7af924-10ab-496c-8cad-7704d2734395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('reading masked data...')\n",
    "with open('./data/light-masked_heavy-mutated.txt') as f:\n",
    "    lmasked_hmutated_txt = [line.strip() for line in f]\n",
    "lmasked_hmutated = [tokenizer(l, return_tensors='pt').to(\"cuda\") for l in lmasked_hmutated_txt]\n",
    "\n",
    "print('running inference:')\n",
    "lmasked_hmutated_data = infer(model,\n",
    "                              tokenizer,\n",
    "                              pair_ids,\n",
    "                              lmasked_hmutated,\n",
    "                              paired_labels,\n",
    "                              lgerm_labels,\n",
    "                             )\n",
    "\n",
    "print('writing output...')\n",
    "lmasked_hmutated_df = pd.DataFrame(lmasked_hmutated_data)\n",
    "lmasked_hmutated_df.to_csv('./outputs/BALM-paired/light-masked_heavy-mutated.csv',\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1d5ca-5b77-468f-b779-2bb701b3375a",
   "metadata": {},
   "source": [
    "#### germline reverted heavy chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb253e5-0357-407c-98ea-e776c9cdc687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('reading masked data...')\n",
    "with open('./data/light-masked_heavy-reverted.txt') as f:\n",
    "    lmasked_hreverted_txt = [line.strip() for line in f]\n",
    "lmasked_hreverted = [tokenizer(l, return_tensors='pt').to(\"cuda\") for l in lmasked_hreverted_txt]\n",
    "\n",
    "print('running inference:')\n",
    "lmasked_hreverted_data = infer(model,\n",
    "                              tokenizer,\n",
    "                              pair_ids,\n",
    "                              lmasked_hreverted,\n",
    "                              paired_labels,\n",
    "                              lgerm_labels\n",
    "                              )\n",
    "\n",
    "print('writing output...')\n",
    "lmasked_hreverted_df = pd.DataFrame(lmasked_hreverted_data)\n",
    "lmasked_hreverted_df.to_csv('./outputs/BALM-paired/light-masked_heavy-reverted.csv',\n",
    "                           index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
