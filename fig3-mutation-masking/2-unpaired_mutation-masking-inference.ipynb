{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c556d60-87f0-452c-9fb6-c1fb881d97ef",
   "metadata": {},
   "source": [
    "# Mutation masking inference for BALM-unpaired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e3638a-ff3f-479e-80e5-b7b18bae5a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf9f11b-012f-4370-b557-dcd7f3358938",
   "metadata": {},
   "source": [
    "## load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279516b-99bd-4bef-b9f0-3d562bfa03c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# replace with actual model path\n",
    "model_path = './BALM-unpaired/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1260b10-d9d1-41b4-92f8-15cc6114a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMaskedLM.from_pretrained(model_path).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9eb5bb-d303-449b-8dd3-ce7646da8f93",
   "metadata": {},
   "source": [
    "## tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132c633a-f7df-4c1b-84de-771f506f9e13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('../tokenizer/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e815387-12a9-422e-9093-cf4247734e0d",
   "metadata": {},
   "source": [
    "## inference function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecc085-a2b0-41cf-9d8d-25fc89a28583",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def infer(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    pair_ids, \n",
    "    inputs, \n",
    "    labels, \n",
    "    #germs,\n",
    "    device='cuda'\n",
    "):\n",
    "    '''\n",
    "    inputs and labels should already be tokenized\n",
    "    \n",
    "    labels should just be the 'input_ids' data, not the whole tokenized dict\n",
    "    '''\n",
    "    data = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(list(zip(pair_ids, inputs, labels)))\n",
    "        # pbar = tqdm(list(zip(pair_ids, inputs, labels, germs)))\n",
    "        # for name, i, l, g in pbar:\n",
    "        for name, i, l in pbar:\n",
    "            mask_positions = (i.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)\n",
    "            labels_ = torch.where(i.input_ids == tokenizer.mask_token_id, l, -100)\n",
    "            o = model(**i, labels=labels_)\n",
    "            \n",
    "            # loss\n",
    "            loss = o.loss.item()\n",
    "            \n",
    "            # PPL\n",
    "            perplexity = float(torch.exp(o.loss))\n",
    "            \n",
    "            # germlines\n",
    "            # germs_ = torch.where(i.input_ids == tokenizer.mask_token_id, g, -100)\n",
    "            # germ_tokens = [germs_[0, mask_pos] for mask_pos in mask_positions]\n",
    "            # germ = [tokenizer.decode(germ_token) for germ_token in germ_tokens]\n",
    "            # germ = \"\".join(germ)\n",
    "            \n",
    "            # ground truth\n",
    "            actual_tokens = [labels_[0, mask_pos] for mask_pos in mask_positions]\n",
    "            actual = [tokenizer.decode(actual_token) for actual_token in actual_tokens]\n",
    "            actual = \"\".join(actual)\n",
    "            \n",
    "            # logits\n",
    "            logits = [o.logits[0, mask_pos] for mask_pos in mask_positions][0]\n",
    "            m = torch.nn.Softmax(dim=1)\n",
    "            softmax = m(logits)\n",
    "            \n",
    "            # predictions\n",
    "            pred_tokens = logits.argmax(axis=-1)\n",
    "            preds = [tokenizer.decode(pred_token) for pred_token in pred_tokens]\n",
    "            predictions = ''.join(preds)\n",
    "            \n",
    "            # format and append data\n",
    "            for x in range(len(mask_positions[0])):\n",
    "                d = {\n",
    "                    \"pair_id\": name,\n",
    "                    \"perplexity\": perplexity,\n",
    "                    \"loss\": loss,\n",
    "                    \"mask_position\": mask_positions[0][x].item(),\n",
    "                    \"prediction\": predictions[x],\n",
    "                    #\"germline\": germ[x],\n",
    "                    \"actual\": actual[x],\n",
    "                }\n",
    "                for y in range(tokenizer.vocab_size):\n",
    "                    _d = copy.deepcopy(d)\n",
    "                    token = tokenizer.decode(y)\n",
    "                    _d[\"token\"] = token\n",
    "                    _d[\"logit\"] = logits[x, y].item()\n",
    "                    _d[\"softmax\"] = softmax[x, y].item()\n",
    "                    data.append(_d)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc21508-90bf-4285-ab49-ac4bbcd4bfef",
   "metadata": {},
   "source": [
    "## load labels & tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5868a07-bd0d-471b-b09e-d8df73a7a4f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pair ids\n",
    "with open('./data/pair_ids.txt') as f:\n",
    "    pair_ids = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d58053-88ed-4055-b7a3-b9afb68ba52e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# labels\n",
    "with open('./data/heavy_labels.txt') as f:\n",
    "    heavy_labels_txt = [line.strip() for line in f]\n",
    "heavy_labels = [tokenizer(l, return_tensors='pt').to('cuda')['input_ids'] for l in heavy_labels_txt]\n",
    "\n",
    "with open('./data/light_labels.txt') as f:\n",
    "    light_labels_txt = [line.strip() for line in f]\n",
    "light_labels = [tokenizer(l, return_tensors='pt').to('cuda')['input_ids'] for l in light_labels_txt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4dd953-e736-4e04-809b-f1b408a87006",
   "metadata": {},
   "source": [
    "## masked heavy chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ed392-bf52-48e4-9d60-b2e8ca4f58cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('reading masked data...')\n",
    "with open('./data/heavy-masked.txt') as f:\n",
    "    hmasked_txt = [line.strip() for line in f]\n",
    "hmasked = [tokenizer(l, return_tensors='pt').to(\"cuda\") for l in hmasked_txt]\n",
    "\n",
    "print('running inference:')\n",
    "hmasked_data = infer(model,\n",
    "                     tokenizer,\n",
    "                     pair_ids,\n",
    "                     hmasked,\n",
    "                     heavy_labels,\n",
    "                    )\n",
    "\n",
    "print('writing output...')\n",
    "hmasked_df = pd.DataFrame(hmasked_data)\n",
    "hmasked_df.to_csv('./outputs/BALM-unpaired/heavy-masked.csv',\n",
    "                           index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276d06ff-0a01-4e6d-822f-409ec9ac79e0",
   "metadata": {},
   "source": [
    "## masked light chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62342217-e796-45d4-877f-d2ca137fa769",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('reading masked data...')\n",
    "with open('./data/light-masked.txt') as f:\n",
    "    lmasked_txt = [line.strip() for line in f]\n",
    "lmasked = [tokenizer(l, return_tensors='pt').to(\"cuda\") for l in lmasked_txt]\n",
    "\n",
    "print('running inference:')\n",
    "lmasked_data = infer(model,\n",
    "                     tokenizer,\n",
    "                     pair_ids,\n",
    "                     lmasked,\n",
    "                     light_labels,\n",
    "                    )\n",
    "\n",
    "print('writing output...')\n",
    "lmasked_df = pd.DataFrame(lmasked_data)\n",
    "lmasked_df.to_csv('./outputs/BALM-unpaired/light-masked.csv',\n",
    "                           index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
